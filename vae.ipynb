{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Sam Armstrong CS548 Project</center></h1>\n",
    "<h1><center>Variational Autoencoder with Classifier</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load RNA-Seq Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq_data = pd.read_csv(\"tumor_data/data.csv\")\n",
    "seq_data.rename(columns={'Unnamed: 0':'sample'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tumor Type/Class Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"tumor_data/labels.csv\")\n",
    "labels.rename(columns={'Unnamed: 0':'sample'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join RNA-Seq and Tumor Type/Class Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_data = seq_data.set_index('sample').join(labels.set_index('sample')).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Pytorch Dataset for Cancer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TumorDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data, transform=None):\n",
    "        'Initialization'\n",
    "        self.labels = data[:, -1]\n",
    "        self.lookup_table, self.labels = np.unique(data[:, -1], return_inverse=True)\n",
    "        self.genes = data[:, :-1]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Load data and get label\n",
    "        X = torch.from_numpy(self.genes[index, : ].astype(np.float)).float()\n",
    "        y = torch.from_numpy(np.unique(self.labels[index]).astype(int))\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        return F.relu(self.linear2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        return F.relu(self.linear2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.linears = torch.nn.ModuleList([torch.nn.Linear(D_in, H[0])])\n",
    "        \n",
    "        for i in range(1,len(H)):\n",
    "            self.linears.append(torch.nn.Linear(H[i-1], H[i]))\n",
    "            \n",
    "        self.linears.append(torch.nn.Linear(H[-1], D_out))\n",
    "  \n",
    "    def forward(self, x):\n",
    "        for h in self.linears:\n",
    "            x = h(x)\n",
    "       \n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoder Class with Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, classifier, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.classifier = classifier\n",
    "        self._enc_mu = torch.nn.Linear(self.encoder.linear2.out_features, latent_dim)\n",
    "        self._enc_log_sigma = torch.nn.Linear(self.encoder.linear2.out_features, latent_dim)\n",
    "\n",
    "    def _sample_latent(self, h_enc):\n",
    "        \"\"\"\n",
    "        Return the latent normal sample z ~ N(mu, sigma^2)\n",
    "        \"\"\"\n",
    "        mu = self._enc_mu(h_enc)\n",
    "        log_sigma = self._enc_log_sigma(h_enc)\n",
    "        sigma = torch.exp(log_sigma)\n",
    "        std_z = torch.from_numpy(np.random.normal(0, 1, size=sigma.size())).float()\n",
    "\n",
    "        self.z_mean = mu\n",
    "        self.z_sigma = sigma\n",
    "\n",
    "        return mu + sigma * Variable(std_z, requires_grad=False)  \n",
    "    \n",
    "    \n",
    "    def forwardEncoder(self, state):\n",
    "        h_enc = self.encoder(state)\n",
    "        return self._sample_latent(h_enc)\n",
    "    \n",
    "    def forwardAutoEncoder(self, state):\n",
    "        z = self.forwardEncoder(state)\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def forwardClassifier(self, state):\n",
    "        z = self.forwardEncoder(state)\n",
    "        return self.classifier(z)\n",
    "    \n",
    "    def saveModel(self, fileName=\"vaeModel\"):\n",
    "        torch.save(self.state_dict(), fileName)\n",
    "        print(\"Model Saved Successfully\")\n",
    "        \n",
    "    def loadModel(self, fileName=\"vaeModel\"):\n",
    "        self.load_state_dict(torch.load(fileName))\n",
    "        self.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss Method (Kullbackâ€“Leibler Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_loss(z_mean, z_stddev):\n",
    "    mean_sq = z_mean * z_mean\n",
    "    stddev_sq = z_stddev * z_stddev\n",
    "    return 0.5 * torch.mean(mean_sq + stddev_sq - torch.log(stddev_sq) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train AutoEncoder (Encoder + Decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAutoencoder(modelName, loadModel=False, saveModel=True, input_dim = 20531, latent_dim = 10, encoding_layer = 100, classifier_layers = [20, 20, 20], n_classes = 5, batch_size = 32, epochs = 10, verbose = True):\n",
    "\n",
    "    encoder = Encoder(input_dim, encoding_layer, encoding_layer)\n",
    "    decoder = Decoder(latent_dim, encoding_layer, input_dim)\n",
    "    classifier = Classifier(latent_dim, classifier_layers, n_classes)\n",
    "\n",
    "    vae = VAE(encoder, decoder, classifier, latent_dim)\n",
    "    \n",
    "    if loadModel:\n",
    "        vae.loadModel(modelName)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader( TumorDataset(tumor_data), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    if verbose:\n",
    "        print('Number of samples: ', len(tumor_data))\n",
    "\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = optim.Adam(vae.parameters(), lr=0.0001)\n",
    "\n",
    "    l = None\n",
    "    for epoch in range(epochs):\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, classes = data\n",
    "            inputs, classes = Variable(inputs.resize_(batch_size, input_dim)), Variable(classes)\n",
    "            optimizer.zero_grad()\n",
    "            dec = vae.forwardAutoEncoder(inputs.float())\n",
    "            ll = latent_loss(vae.z_mean, vae.z_sigma)\n",
    "            loss = criterion(dec, inputs) + ll\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            l = loss.item()\n",
    "        if verbose:\n",
    "            print(epoch, l)\n",
    "\n",
    "    if saveModel:\n",
    "        vae.saveModel(modelName + \"_loss-\" + str(l) + \"_CIvec-\" + str(latent_dim) + \"_class-\" + str(classifier_layers).replace(\"[\", \"\").replace(\"]\", \"\").replace(\", \", \".\"))\n",
    "        \n",
    "    return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  801\n",
      "0 1.7864315509796143\n",
      "1 1.6781020164489746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Encoder(\n",
       "    (linear1): Linear(in_features=20531, out_features=100, bias=True)\n",
       "    (linear2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (linear1): Linear(in_features=10, out_features=100, bias=True)\n",
       "    (linear2): Linear(in_features=100, out_features=20531, bias=True)\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=10, out_features=20, bias=True)\n",
       "      (1): Linear(in_features=20, out_features=20, bias=True)\n",
       "      (2): Linear(in_features=20, out_features=20, bias=True)\n",
       "      (3): Linear(in_features=20, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (_enc_mu): Linear(in_features=100, out_features=10, bias=True)\n",
       "  (_enc_log_sigma): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainAutoencoder(\"testModel\", saveModel=False, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Classifier (Encoder + Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainClassifier(modelName, loadModel=False, saveModel=True, input_dim = 20531, latent_dim = 10, encoding_layer = 100, classifier_layers = [20, 20, 20], n_classes = 5, batch_size = 32, epochs = 10, verbose = True):\n",
    "    \n",
    "    encoder = Encoder(input_dim, encoding_layer, encoding_layer)\n",
    "    decoder = Decoder(latent_dim, encoding_layer, input_dim)\n",
    "    classifier = Classifier(latent_dim, classifier_layers, n_classes)\n",
    "\n",
    "    vae = VAE(encoder, decoder, classifier, latent_dim)\n",
    "    \n",
    "    if loadModel:\n",
    "        vae.loadModel(modelName)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader( TumorDataset(tumor_data), batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    if verbose:\n",
    "        print('Number of samples: ', len(tumor_data))\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.Adam(vae.parameters(), lr=0.0001)\n",
    "\n",
    "    l = None\n",
    "    for epoch in range(epochs):\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, classes = data\n",
    "            inputs, classes = Variable(inputs.resize_(batch_size, input_dim)), Variable(classes).flatten().long()\n",
    "            predictions = vae.forwardClassifier(inputs.float())\n",
    "            optimizer.zero_grad()\n",
    "            ll = latent_loss(vae.z_mean, vae.z_sigma)\n",
    "            loss = criterion(predictions, classes) + ll\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            l = loss.item()\n",
    "        if verbose:\n",
    "            print(epoch, l)\n",
    "        \n",
    "    if saveModel:\n",
    "        vae.saveModel(modelName + \"_loss-\" + str(l) + \"_CIvec-\" + str(latent_dim) + \"_class-\" + str(classifier_layers).replace(\"[\", \"\").replace(\"]\", \"\").replace(\", \", \".\"))\n",
    "        \n",
    "    return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  801\n",
      "0 8.114500045776367\n",
      "1 2.53641414642334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Encoder(\n",
       "    (linear1): Linear(in_features=20531, out_features=100, bias=True)\n",
       "    (linear2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (linear1): Linear(in_features=10, out_features=100, bias=True)\n",
       "    (linear2): Linear(in_features=100, out_features=20531, bias=True)\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=10, out_features=20, bias=True)\n",
       "      (1): Linear(in_features=20, out_features=20, bias=True)\n",
       "      (2): Linear(in_features=20, out_features=20, bias=True)\n",
       "      (3): Linear(in_features=20, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (_enc_mu): Linear(in_features=100, out_features=10, bias=True)\n",
       "  (_enc_log_sigma): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainClassifier(\"testModel\", saveModel=False, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Classifier Percentage Correct on Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printClassifierAccuracy(model, input_dim = 20531, batch_size = 32):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    train_loader = torch.utils.data.DataLoader( TumorDataset(tumor_data), batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, classes = data\n",
    "        inputs, classes = Variable(inputs.resize_(batch_size, input_dim)), Variable(classes).flatten().long()\n",
    "        predictions = model.forwardClassifier(inputs.float())\n",
    "        _, predicted = torch.max(predictions.data, 1)\n",
    "        total += classes.size(0)\n",
    "        correct += (predicted == classes).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the training data: %d %%' % (\n",
    "        100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  801\n",
      "0 2.433783531188965\n",
      "1 1.7174665927886963\n",
      "Accuracy of the network on the training data: 36 %\n"
     ]
    }
   ],
   "source": [
    "model = trainClassifier(\"testModel\", saveModel=False, epochs=2)\n",
    "printClassifierAccuracy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dimension = range(8, 33)\n",
    "classifiers = [[10]*2, [10]*3, [10]*4, [10]*5, \n",
    "               [20]*2, [20]*3, [20]*4, [20]*5, \n",
    "               [30]*2, [30]*3, [30]*4, [30]*5,\n",
    "               [40]*2, [40]*3, [40]*4, [40]*5,\n",
    "               [50]*2, [50]*3, [50]*4, [50]*5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  801\n",
      "0 1.6529542207717896\n",
      "1 1.6119574308395386\n",
      "2 1.606869101524353\n",
      "3 1.5993549823760986\n",
      "4 1.6041462421417236\n",
      "5 1.5879263877868652\n",
      "6 1.600173830986023\n",
      "7 1.6029385328292847\n",
      "8 1.5934261083602905\n",
      "9 1.6006280183792114\n",
      "10 1.6160714626312256\n",
      "11 1.6159781217575073\n",
      "12 1.6146551370620728\n",
      "13 1.5885255336761475\n",
      "14 1.5997686386108398\n",
      "15 1.593442440032959\n",
      "16 1.5971723794937134\n",
      "17 1.5994203090667725\n",
      "18 1.5861436128616333\n",
      "19 1.5977225303649902\n",
      "20 1.5915696620941162\n",
      "21 1.5949057340621948\n",
      "22 1.5961037874221802\n",
      "23 1.56308913230896\n",
      "24 1.5670340061187744\n",
      "25 1.5961098670959473\n",
      "26 1.5612330436706543\n",
      "27 1.594193696975708\n",
      "28 1.564295768737793\n",
      "29 1.5980618000030518\n",
      "30 1.570786714553833\n",
      "31 1.5490353107452393\n",
      "32 1.5735511779785156\n",
      "33 1.5881454944610596\n",
      "34 1.5916306972503662\n",
      "35 1.5609742403030396\n",
      "36 1.549248456954956\n",
      "37 1.5477168560028076\n",
      "38 1.5968376398086548\n",
      "39 1.5935728549957275\n",
      "40 1.5871813297271729\n",
      "41 1.5579156875610352\n",
      "42 1.5814383029937744\n",
      "43 1.5657665729522705\n",
      "44 1.5917474031448364\n",
      "45 1.6107171773910522\n",
      "46 1.5004799365997314\n",
      "47 1.5957247018814087\n",
      "48 1.528151273727417\n",
      "49 1.4983431100845337\n",
      "50 1.5381824970245361\n",
      "51 1.55536687374115\n",
      "52 1.624613881111145\n",
      "53 1.5341366529464722\n",
      "54 1.5810896158218384\n",
      "55 1.546800136566162\n",
      "56 1.5260944366455078\n",
      "57 1.5732216835021973\n",
      "58 1.5547292232513428\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-09d67fa30c65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlatent_dimension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mtrainClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"vaeModel1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-80432355e82e>\u001b[0m in \u001b[0;36mtrainClassifier\u001b[1;34m(modelName, loadModel, saveModel, input_dim, latent_dim, encoding_layer, classifier_layers, n_classes, batch_size, epochs, verbose)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-3490b5054e13>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;34m'Generates one sample of data'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# Load data and get label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in latent_dimension:\n",
    "    for c in classifiers:\n",
    "        trainClassifier(\"vaeModel1\", epochs=300, latent_dim=i, classifier_layers=c, verbose=False)\n",
    "        print(\"Model Complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
